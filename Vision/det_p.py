
import os
import numpy as np
import pandas as pd
import cv2
print(cv2.__version__)
import random
import matplotlib.pyplot as plt
# import dlib
import mediapipe as mp
import time

# mpHands = mp.solutions.hands        # mediapipeë¡œ ë¶€í„° handsëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# hands = mpHands.Hands()             # handsëª¨ë¸ë¡œ ë¶€í„° Handsë¼ëŠ” ì†ì„ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
mp_pose = mp.solutions.pose
poses = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_Draw = mp.solutions.drawing_utils # mediapipeë¡œ ë¶€í„° ê²°ê³¼ ê°’ì„ imageì— ê·¸ë ¤ ë„£ëŠ” í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
mp_drawing_styles = mp.solutions.drawing_styles

count_time = 0                      # fpsë¥¼ ê³„ì‚°í•  ë³€ìˆ˜ë¥¼ ì„ ì–¸í•©ë‹ˆë‹¤.
elapsed_time = 0


def calculate_angle(a,b,c):
    # ê° ê°’ì„ ë°›ì•„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í˜•
    a = np.array(a) # ì²«ë²ˆì§¸
    b = np.array(b) # ë‘ë²ˆì§¸
    c = np.array(c) # ì„¸ë²ˆì§¸
    # ë¼ë””ì•ˆì„ ê³„ì‚°í•˜ê³  ì‹¤ì œ ê°ë„ë¡œ ë³€ê²½í•œë‹¤.
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    # 180ë„ê°€ ë„˜ìœ¼ë©´ 360ì—ì„œ ëº€ ê°’ì„ ê³„ì‚°í•œë‹¤.
    if angle >180.0:
        angle = 360-angle
    # ê°ë„ë¥¼ ë¦¬í„´í•œë‹¤.
    return angle

# ê²°ë¡¸ë¡œ ì €ì¥í•  ë™ì˜ìƒ ì´ë¦„
save_result = None #'/results/handpose.mp4'

# ë¶„ì„í•  ë™ì˜ìƒ ì´ë¦„
file_name = '/home/augustine77/Lab_2024/p01_base/SVU_industrial_AI/Vision/store/ìŠ¬ë¡œìš°ëª¨ì…˜ ì •ë©´ [ì´ë„í˜•í”„ë¡œ].mp4'
# '/home/augustine77/Lab_2024/p01_base/SVU_industrial_AI/Vision/store/[ê³¨í”„ìŠ¤ìœ™] 7ë²ˆì•„ì´ì–¸ ìŠ¬ë¡œìš°ëª¨ì…˜.mp4'
# '/home/augustine77/Lab_2024/p01_base/SVU_industrial_AI/Vision/store/ë“œë¼ì´ë²„ìŠ¤ìœ™ í”¼ë‹ˆì‰¬ëŠ” ì™¼ë°œë’·ê¿ˆì¹˜ì— ì²´ì¤‘ì‹£ê¸°.mp4'
# '/home/augustine77/Lab_2024/p01_base/SVU_industrial_AI/Vision/store/ìŠ¬ë¡œìš°ëª¨ì…˜ ì •ë©´ [ì´ë„í˜•í”„ë¡œ].mp4'
# '/home/augustine77/Lab_2024/p01_base/SVU_industrial_AI/Vision/store/ìŠ¬ë¡œìš°ëª¨ì…˜ì´ ì •ë§ ë©‹ì§‘ë‹ˆë‹¤!!ğŸ‘ğŸ‘ KLPGA í™©ì•„ë¦„ í”„ë¡œ ë“œë¼ì´ë²„ ìŠ¤ìœ™. instagram@areum2klpga.mp4'


 # ë¶„ì„ ë™ì˜ìƒ mp4 ì½ì–´ì˜¤ê¸°
cap = cv2.VideoCapture(file_name)
idx = 0

# ì¬ìƒí•  íŒŒì¼ì˜ ë„“ì´ì™€ ë†’ì´ ì½ì–´ ë‘ê¸°
width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
fps = cap.get(cv2.CAP_PROP_FPS)


save_data = "./data"
if not os.path.exists(save_data):
    os.mkdir(save_data)

name = input("Insert Video Name(Only Alphabet):")
id = input("Insert Id(Non-Duplicate number):")

data_file = f"{id}_{name}.xlsx"

col = ['id','name','frame_idx','angle','frame_time']
df = pd.DataFrame(columns=col)

# dir = os.path.join(base_dir, name+'_'+ id)
# if not os.path.exists(dir):
#     os.mkdir(dir)


# ì¶œë ¥ ì˜ìƒ ë‹¤ì‹œ ì €ì¥í•  ê°ì²´ ìƒì„±
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
writer = cv2.VideoWriter(save_result, fourcc, fps, (int(width), int(height)),True)
print("ì¬ìƒí•  íŒŒì¼ ë„“ì´, ë†’ì´ : %d, %d"%(width, height))

if not cap.isOpened:
    print('--(!)Error opening video capture')
    exit(0)


with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
    while (cap.isOpened()):
        start_time = time.time()
        idx += 1
        success, frame = cap.read()    

        if frame is None:                                   # ë™ì˜ìƒì˜ frameì´ ì—†ìœ¼ë©´ ë¶„ì„ì„ ëëƒ…ë‹ˆë‹¤..
            # close the video file pointers
            cap.release()
            # close the writer point
            writer.release()
            print('--(!) No captured frame -- Break!')
            print("elapsed time {:.3f} seconds".format(elapsed_time))
            break
        if success == False:
            break

        # Recolor image to RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #BGR í¬ë§·ì—ì„œ RGB í¬ë§·ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.
        frame.flags.writeable = False

        # Make detection poses
        results_poses = poses.process(frame)

        # if results_hands.multi_hand_landmarks:                    # ì½ì–´ ë“œë¦° ê²°ê³¼ ì¤‘ ì†ì˜ landmark ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì§„í–‰í•©ë‹ˆë‹¤.
        #     for handLMK in results_hands.multi_hand_landmarks:    # ì½ì–´ ë“œë¦° ê²°ê³¼ì—ì„œ ì°¾ì€ ì†ì˜ ìˆ˜(ì‚¬ìš©ì ì§€ì • ê¸°ë³¸ 2)ë§Œí¼ ìˆœí™˜ ì§„í–‰
        #         for id, lmk in enumerate(handLMK.landmark): # ì½ì–´ ë“œë¦° ì†ì˜ ê²°ê³¼ì˜ landmark ìˆ˜ë§Œí¼ ìˆœí™˜ ì§„í–‰
        #             # print(id, lmk)
        #             h, w, c = frame.shape                                     # ì›ë³¸ ì´ë¯¸ì§€ì˜ í¬ê¸°
        #             cx, cy = int(lmk.x*w), int(lmk.y*h)                     # í•´ë‹¹ landmarkì˜ ì¢Œí‘œê°’ì„ ê³±í•´ì„œ í‘œì‹œí•  ìœ„ì¹˜ í™•ì¸
        #             # print(id, cx, cy)                                       # í•´ë‹¹ landmarkì˜ ìœ„ì¹˜ í‘œì‹œ
        #             if id==0:                                               # í‘œì‹œí•˜ê³  ì‹¶ì€ ì†ì˜ landmark ìœ„ì¹˜ ì§€ì • í˜„ì¬ëŠ” ì†ë°”ë‹¥ ì¤‘ì‹¬(0ë²ˆ)
        #                 cv2.circle(frame,(cx,cy),15,(255,0,255),cv2.FILLED )  # í•´ë‹¹ ìœ„ì¹˜ì— ì› í‘œì‹œ
        #         mp_Draw.draw_landmarks(frame, handLMK, mpHands.HAND_CONNECTIONS
        #                               ,mp_drawing_styles.get_default_hand_landmarks_style()
        #                               ,mp_drawing_styles.get_default_hand_connections_style()) # mediapipe  draw í´ë˜ìŠ¤ë¡œ landmark ìœ„ì¹˜ì ë“¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°

        if results_poses.pose_landmarks.landmark:
            landmarks = results_poses.pose_landmarks.landmark
            # Get coordinates
            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
            
            # Calculate angle
            angle = calculate_angle(shoulder,elbow, wrist)

            # Visualize angle
            cv2.putText(frame, str(angle), 
                            tuple(np.multiply(elbow, [640, 480]).astype(int)), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA
                                )
        else:
            pass


        # Render detections
        mp_Draw.draw_landmarks(frame, results_poses.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                                mp_Draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), 
                                mp_Draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) 
                                    )
        
        # frame = cv2.resize(frame, (900, 600))         


        # Recolor back to BGR
        frame.flags.writeable = True
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)


        elapsed_time = time.time()
        fps = 1/(elapsed_time-count_time)                                      # í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        count_time = elapsed_time

        # frame = cv2.flip(frame,1)
        cv2.putText(frame,str(int(fps)),(20,140),cv2.FONT_HERSHEY_PLAIN        # í”„ë ˆì„ ì²˜ë¦¬ì‹œê°„ í‘œì‹œ
                    , 3, (255,0,255),3)

        process_time = time.time() - start_time
        elapsed_time += process_time   # ì´ ê²½ê³¼ì‹œê°„ ëˆ„ì 
        print("=== A idx {:d} frame took {:.3f} seconds".format(idx,process_time))

        data = [[id,name,idx,angle,process_time]]
        frame_data = pd.DataFrame(data,columns=col)

        # df.stack(frame_data,1)
        df = pd.concat([df,frame_data],axis=0)

        # frameì˜ ì €ì¥
        if save_result is not None:
            writer.write(frame)

        cv2.imshow('frame', frame)
        if cv2.waitKey(10) == 27:
            break

    df.to_excel(os.path.join(save_data,data_file), header=True, index=False)

    cap.release()
    writer.release()
    cv2.destroyAllWindows()